{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcc9d91-796b-4e20-882d-4885e528a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import stat\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import random\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow.keras.backend \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fba599d-85cf-4a1e-873c-fc072b0cfe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to generate directory-file map. \n",
    "def gen_dir_file_map(path):\n",
    "    dir_files = defaultdict(list)\n",
    "    with open(path, 'r') as txt:\n",
    "        files = [i.strip() for i in txt.readlines()]\n",
    "        for f in files:\n",
    "            dir_name, id = f.split('/')\n",
    "            dir_files[dir_name].append(id + '.jpg')\n",
    "    return dir_files\n",
    "\n",
    "# Method to recursively copy a directory.  \n",
    "def copytree(source, target, symlinks=False, ignore=None):\n",
    "    if not os.path.exists(target):\n",
    "        os.makedirs(target)\n",
    "        shutil.copystat(source, target)\n",
    "    data = os.listdir(source)\n",
    "    if ignore:\n",
    "        exclude = ignore(source, data)\n",
    "        data = [x for x in data if x not in exclude]\n",
    "    for item in data:\n",
    "        src = os.path.join(source, item)\n",
    "        dest = os.path.join(target, item)\n",
    "        if symlinks and os.path.islink(src):\n",
    "            if os.path.lexists(dest):\n",
    "                os.remove(dest)\n",
    "            os.symlink(os.readlink(src), dest)\n",
    "            try:\n",
    "                st = os.lstat(src)\n",
    "                mode = stat.S_IMODE(st.st_mode)\n",
    "                os.lchmod(dest, mode)\n",
    "            except:\n",
    "                pass\n",
    "        elif os.path.isdir(src):\n",
    "            copytree(src, dest, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(src, dest)\n",
    "\n",
    "# Train files to ignore. \n",
    "def ignore_train(d, filenames):\n",
    "    subdir = d.split('/')[-1]\n",
    "    train_dir_files = gen_dir_file_map(\"C:/Users/kurt_/Desktop/food-101/meta/train.txt\")\n",
    "    to_ignore = train_dir_files[subdir]\n",
    "    return to_ignore\n",
    "\n",
    "# Test files to ignore.    \n",
    "def ignore_test(d, filenames):\n",
    "    subdir = d.split('/')[-1]\n",
    "    test_dir_files = gen_dir_file_map(\"C:/Users/kurt_/Desktop/food-101/meta/test.txt\")\n",
    "    to_ignore = test_dir_files[subdir]\n",
    "    return to_ignore\n",
    "\n",
    "# Method to generate train-test files. \n",
    "def gen_train_test_split(path_to_imgs=\"C:/Users/kurt_/Desktop/food-101/images\", target_path=\"C:/Users/kurt_/Desktop/food-101\", meta_path=\"C:/Users/kurt_/Desktop/food-101/meta\"):\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "    train_path = os.path.join(target_path, 'train')\n",
    "    test_path = os.path.join(target_path, 'test')\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "    if not os.path.exists(test_path):\n",
    "        os.makedirs(test_path)\n",
    "    copytree(path_to_imgs, train_path, ignore=ignore_test)\n",
    "    copytree(path_to_imgs, test_path, ignore=ignore_train)\n",
    "\n",
    "# Method to load and resize images.  \n",
    "def load_images(path_to_imgs, image_size=(331, 331)):\n",
    "    resize_count = 0\n",
    "    invalid_count = 0\n",
    "    all_imgs = []\n",
    "    all_classes = []\n",
    "\n",
    "    for subdir in os.listdir(path_to_imgs):\n",
    "        classN = subdir\n",
    "        subdir_path = os.path.join(path_to_imgs, subdir)\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "            img_arr = cv2.imread(img_path)\n",
    "            img_arr_rs = cv2.resize(img_arr, image_size, interpolation=cv2.INTER_AREA)\n",
    "            resize_count += 1\n",
    "            im_rgb = cv2.cvtColor(img_arr_rs, cv2.COLOR_BGR2RGB)\n",
    "            all_imgs.append(im_rgb)\n",
    "            all_classes.append(classN)\n",
    "  \n",
    "    return np.array(all_imgs), np.array(all_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71693b13-e1ca-4706-af55-0827426249fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test folders already exist.\n",
      "101 101\n"
     ]
    }
   ],
   "source": [
    "# Method to load train-test files.\n",
    "def load_train_test_data(path_to_train_imgs, path_to_test_imgs):\n",
    "    X_train, y_train = load_images(path_to_train_imgs)\n",
    "    X_test, y_test = load_images(path_to_test_imgs)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Generate train-test files. \n",
    "if not os.path.isdir(\"C:/Users/kurt_/Desktop/food-101/test\") and not os.path.isdir(\"C:/Users/kurt_/Desktop/food-101/train\"):\n",
    "    gen_train_test_split()  \n",
    "    len_train = len(os.listdir(\"C:/Users/kurt_/Desktop/food-101/train\"))\n",
    "    len_test = len(os.listdir(\"C:/Users/kurt_/Desktop/food-101/test\"))\n",
    "    print(len_train, len_test)\n",
    "else:\n",
    "    print('train and test folders already exist.')\n",
    "    len_train = len(os.listdir(\"C:/Users/kurt_/Desktop/food-101/train\"))\n",
    "    len_test = len(os.listdir(\"C:/Users/kurt_/Desktop/food-101/test\"))\n",
    "    print(len_train, len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb191c1-eabc-4051-b12f-534b6ee33f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101000 images belonging to 101 classes.\n",
      "Found 101000 images belonging to 101 classes.\n",
      "Epoch 1/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 3.1398 - accuracy: 0.2998Epoch 1, Loss: 3.1398, Accuracy: 0.2998, Val Loss: 3.0156, Val Accuracy: 0.3599\n",
      "4734/4734 [==============================] - 1541s 323ms/step - loss: 3.1398 - accuracy: 0.2998 - val_loss: 3.0156 - val_accuracy: 0.3599\n",
      "Epoch 2/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 2.3717 - accuracy: 0.4710Epoch 2, Loss: 2.3717, Accuracy: 0.4710, Val Loss: 2.3499, Val Accuracy: 0.5026\n",
      "4734/4734 [==============================] - 1496s 316ms/step - loss: 2.3717 - accuracy: 0.4710 - val_loss: 2.3499 - val_accuracy: 0.5026\n",
      "Epoch 3/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 2.0716 - accuracy: 0.5485Epoch 3, Loss: 2.0716, Accuracy: 0.5485, Val Loss: 1.9545, Val Accuracy: 0.5899\n",
      "4734/4734 [==============================] - 1479s 312ms/step - loss: 2.0716 - accuracy: 0.5485 - val_loss: 1.9545 - val_accuracy: 0.5899\n",
      "Epoch 4/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.8694 - accuracy: 0.5985Epoch 4, Loss: 1.8694, Accuracy: 0.5985, Val Loss: 1.9194, Val Accuracy: 0.5945\n",
      "4734/4734 [==============================] - 1478s 312ms/step - loss: 1.8694 - accuracy: 0.5985 - val_loss: 1.9194 - val_accuracy: 0.5945\n",
      "Epoch 5/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.7182 - accuracy: 0.6351Epoch 5, Loss: 1.7182, Accuracy: 0.6351, Val Loss: 1.6078, Val Accuracy: 0.6704\n",
      "4734/4734 [==============================] - 1478s 312ms/step - loss: 1.7182 - accuracy: 0.6351 - val_loss: 1.6078 - val_accuracy: 0.6704\n",
      "Epoch 6/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.6082 - accuracy: 0.6626Epoch 6, Loss: 1.6082, Accuracy: 0.6626, Val Loss: 1.2770, Val Accuracy: 0.7441\n",
      "4734/4734 [==============================] - 1505s 318ms/step - loss: 1.6082 - accuracy: 0.6626 - val_loss: 1.2770 - val_accuracy: 0.7441\n",
      "Epoch 7/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.5044 - accuracy: 0.6870Epoch 7, Loss: 1.5044, Accuracy: 0.6870, Val Loss: 1.4759, Val Accuracy: 0.7048\n",
      "4734/4734 [==============================] - 1514s 320ms/step - loss: 1.5044 - accuracy: 0.6870 - val_loss: 1.4759 - val_accuracy: 0.7048\n",
      "Epoch 8/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.4263 - accuracy: 0.7053Epoch 8, Loss: 1.4263, Accuracy: 0.7053, Val Loss: 1.4205, Val Accuracy: 0.7169\n",
      "4734/4734 [==============================] - 1511s 319ms/step - loss: 1.4263 - accuracy: 0.7053 - val_loss: 1.4205 - val_accuracy: 0.7169\n",
      "Epoch 9/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.3607 - accuracy: 0.7214Epoch 9, Loss: 1.3607, Accuracy: 0.7214, Val Loss: 1.1157, Val Accuracy: 0.7795\n",
      "4734/4734 [==============================] - 1513s 319ms/step - loss: 1.3607 - accuracy: 0.7214 - val_loss: 1.1157 - val_accuracy: 0.7795\n",
      "Epoch 10/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.2964 - accuracy: 0.7386Epoch 10, Loss: 1.2964, Accuracy: 0.7386, Val Loss: 1.0429, Val Accuracy: 0.7979\n",
      "4734/4734 [==============================] - 1513s 320ms/step - loss: 1.2964 - accuracy: 0.7386 - val_loss: 1.0429 - val_accuracy: 0.7979\n",
      "Epoch 11/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.2274 - accuracy: 0.7531Epoch 11, Loss: 1.2274, Accuracy: 0.7531, Val Loss: 1.0110, Val Accuracy: 0.8085\n",
      "4734/4734 [==============================] - 1517s 320ms/step - loss: 1.2274 - accuracy: 0.7531 - val_loss: 1.0110 - val_accuracy: 0.8085\n",
      "Epoch 12/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.1824 - accuracy: 0.7638Epoch 12, Loss: 1.1824, Accuracy: 0.7638, Val Loss: 1.0280, Val Accuracy: 0.8053\n",
      "4734/4734 [==============================] - 1525s 322ms/step - loss: 1.1824 - accuracy: 0.7638 - val_loss: 1.0280 - val_accuracy: 0.8053\n",
      "Epoch 13/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.1470 - accuracy: 0.7722Epoch 13, Loss: 1.1470, Accuracy: 0.7722, Val Loss: 1.0717, Val Accuracy: 0.7997\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 1.1470 - accuracy: 0.7722 - val_loss: 1.0717 - val_accuracy: 0.7997\n",
      "Epoch 14/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.7853Epoch 14, Loss: 1.0928, Accuracy: 0.7853, Val Loss: 0.9229, Val Accuracy: 0.8225\n",
      "4734/4734 [==============================] - 1517s 320ms/step - loss: 1.0928 - accuracy: 0.7853 - val_loss: 0.9229 - val_accuracy: 0.8225\n",
      "Epoch 15/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.0627 - accuracy: 0.7911Epoch 15, Loss: 1.0627, Accuracy: 0.7911, Val Loss: 1.0401, Val Accuracy: 0.8047\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 1.0627 - accuracy: 0.7911 - val_loss: 1.0401 - val_accuracy: 0.8047\n",
      "Epoch 16/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 1.0210 - accuracy: 0.8012Epoch 16, Loss: 1.0210, Accuracy: 0.8012, Val Loss: 0.7721, Val Accuracy: 0.8589\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 1.0210 - accuracy: 0.8012 - val_loss: 0.7721 - val_accuracy: 0.8589\n",
      "Epoch 17/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.8095Epoch 17, Loss: 0.9859, Accuracy: 0.8095, Val Loss: 0.7991, Val Accuracy: 0.8552\n",
      "4734/4734 [==============================] - 1520s 321ms/step - loss: 0.9859 - accuracy: 0.8095 - val_loss: 0.7991 - val_accuracy: 0.8552\n",
      "Epoch 18/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.9501 - accuracy: 0.8175Epoch 18, Loss: 0.9501, Accuracy: 0.8175, Val Loss: 0.9148, Val Accuracy: 0.8331\n",
      "4734/4734 [==============================] - 1514s 320ms/step - loss: 0.9501 - accuracy: 0.8175 - val_loss: 0.9148 - val_accuracy: 0.8331\n",
      "Epoch 19/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.9297 - accuracy: 0.8236Epoch 19, Loss: 0.9297, Accuracy: 0.8236, Val Loss: 0.6690, Val Accuracy: 0.8859\n",
      "4734/4734 [==============================] - 1527s 323ms/step - loss: 0.9297 - accuracy: 0.8236 - val_loss: 0.6690 - val_accuracy: 0.8859\n",
      "Epoch 20/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8885 - accuracy: 0.8326Epoch 20, Loss: 0.8885, Accuracy: 0.8326, Val Loss: 0.6590, Val Accuracy: 0.8880\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 0.8885 - accuracy: 0.8326 - val_loss: 0.6590 - val_accuracy: 0.8880\n",
      "Epoch 21/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8638 - accuracy: 0.8359Epoch 21, Loss: 0.8638, Accuracy: 0.8359, Val Loss: 0.6139, Val Accuracy: 0.8960\n",
      "4734/4734 [==============================] - 1521s 321ms/step - loss: 0.8638 - accuracy: 0.8359 - val_loss: 0.6139 - val_accuracy: 0.8960\n",
      "Epoch 22/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.8430Epoch 22, Loss: 0.8372, Accuracy: 0.8430, Val Loss: 0.6997, Val Accuracy: 0.8762\n",
      "4734/4734 [==============================] - 1517s 320ms/step - loss: 0.8372 - accuracy: 0.8430 - val_loss: 0.6997 - val_accuracy: 0.8762\n",
      "Epoch 23/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.8466Epoch 23, Loss: 0.8180, Accuracy: 0.8466, Val Loss: 0.7490, Val Accuracy: 0.8693\n",
      "4734/4734 [==============================] - 1516s 320ms/step - loss: 0.8180 - accuracy: 0.8466 - val_loss: 0.7490 - val_accuracy: 0.8693\n",
      "Epoch 24/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.7892 - accuracy: 0.8547Epoch 24, Loss: 0.7892, Accuracy: 0.8547, Val Loss: 0.5980, Val Accuracy: 0.9011\n",
      "4734/4734 [==============================] - 1523s 322ms/step - loss: 0.7892 - accuracy: 0.8547 - val_loss: 0.5980 - val_accuracy: 0.9011\n",
      "Epoch 25/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.7722 - accuracy: 0.8573Epoch 25, Loss: 0.7722, Accuracy: 0.8573, Val Loss: 0.5489, Val Accuracy: 0.9124\n",
      "4734/4734 [==============================] - 1522s 322ms/step - loss: 0.7722 - accuracy: 0.8573 - val_loss: 0.5489 - val_accuracy: 0.9124\n",
      "Epoch 26/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.7479 - accuracy: 0.8620Epoch 26, Loss: 0.7479, Accuracy: 0.8620, Val Loss: 0.5361, Val Accuracy: 0.9144\n",
      "4734/4734 [==============================] - 1525s 322ms/step - loss: 0.7479 - accuracy: 0.8620 - val_loss: 0.5361 - val_accuracy: 0.9144\n",
      "Epoch 27/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.7290 - accuracy: 0.8665Epoch 27, Loss: 0.7290, Accuracy: 0.8665, Val Loss: 0.4743, Val Accuracy: 0.9263\n",
      "4734/4734 [==============================] - 1520s 321ms/step - loss: 0.7290 - accuracy: 0.8665 - val_loss: 0.4743 - val_accuracy: 0.9263\n",
      "Epoch 28/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.8731Epoch 28, Loss: 0.7016, Accuracy: 0.8731, Val Loss: 0.5371, Val Accuracy: 0.9156\n",
      "4734/4734 [==============================] - 1514s 320ms/step - loss: 0.7016 - accuracy: 0.8731 - val_loss: 0.5371 - val_accuracy: 0.9156\n",
      "Epoch 29/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.8779Epoch 29, Loss: 0.6787, Accuracy: 0.8779, Val Loss: 0.5126, Val Accuracy: 0.9196\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 0.6787 - accuracy: 0.8779 - val_loss: 0.5126 - val_accuracy: 0.9196\n",
      "Epoch 30/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.8824Epoch 30, Loss: 0.6611, Accuracy: 0.8824, Val Loss: 0.5282, Val Accuracy: 0.9153\n",
      "4734/4734 [==============================] - 1513s 320ms/step - loss: 0.6611 - accuracy: 0.8824 - val_loss: 0.5282 - val_accuracy: 0.9153\n",
      "Epoch 31/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.8860Epoch 31, Loss: 0.6495, Accuracy: 0.8860, Val Loss: 0.5560, Val Accuracy: 0.9103\n",
      "4734/4734 [==============================] - 1514s 320ms/step - loss: 0.6495 - accuracy: 0.8860 - val_loss: 0.5560 - val_accuracy: 0.9103\n",
      "Epoch 32/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.8883Epoch 32, Loss: 0.6348, Accuracy: 0.8883, Val Loss: 0.4808, Val Accuracy: 0.9236\n",
      "4734/4734 [==============================] - 1513s 319ms/step - loss: 0.6348 - accuracy: 0.8883 - val_loss: 0.4808 - val_accuracy: 0.9236\n",
      "Epoch 33/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.8921Epoch 33, Loss: 0.6152, Accuracy: 0.8921, Val Loss: 0.4379, Val Accuracy: 0.9372\n",
      "4734/4734 [==============================] - 1522s 321ms/step - loss: 0.6152 - accuracy: 0.8921 - val_loss: 0.4379 - val_accuracy: 0.9372\n",
      "Epoch 34/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.8964Epoch 34, Loss: 0.5961, Accuracy: 0.8964, Val Loss: 0.4122, Val Accuracy: 0.9413\n",
      "4734/4734 [==============================] - 1516s 320ms/step - loss: 0.5961 - accuracy: 0.8964 - val_loss: 0.4122 - val_accuracy: 0.9413\n",
      "Epoch 35/35\n",
      "4734/4734 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.8974Epoch 35, Loss: 0.5898, Accuracy: 0.8974, Val Loss: 0.4743, Val Accuracy: 0.9250\n",
      "4734/4734 [==============================] - 1519s 321ms/step - loss: 0.5898 - accuracy: 0.8974 - val_loss: 0.4743 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LambdaCallback\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Clear Keras session\n",
    "K.clear_session()\n",
    "\n",
    "# Define constants\n",
    "n_classes = 101\n",
    "batch_size = 16\n",
    "width, height = 331, 331\n",
    "train_data = r\"C:\\Users\\kurt_\\Desktop\\food-101\\train\"\n",
    "test_data = r\"C:\\Users\\kurt_\\Desktop\\food-101\\test\"\n",
    "train_samples = 75750\n",
    "test_samples = 25250\n",
    "\n",
    "# Data generators\n",
    "train_data_gen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_gen = train_data_gen.flow_from_directory(train_data, target_size=(height, width), batch_size=batch_size, class_mode='categorical')\n",
    "test_gen = test_data_gen.flow_from_directory(test_data, target_size=(height, width), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# Model\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "layer = inception.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "layer = Dense(128, activation='relu')(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "predictions = Dense(n_classes, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(layer)\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "optimizer = SGD(momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_101class_inceptionv3den3.hdf5', save_best_only=True)\n",
    "csv_logger = CSVLogger('history_101class_inceptionv3den3.log')\n",
    "\n",
    "# Progress print callback\n",
    "def print_progress(epoch, logs):\n",
    "    print(\"Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.4f}\".format(\n",
    "        epoch+1, logs['loss'], logs['accuracy'], logs['val_loss'], logs['val_accuracy']))\n",
    "\n",
    "progress_printer = LambdaCallback(on_epoch_end=print_progress)\n",
    "\n",
    "# Train the model\n",
    "history_101class_inceptionv3den3 = model.fit(train_gen, \n",
    "                             steps_per_epoch=train_samples // batch_size, \n",
    "                             validation_data=test_gen, \n",
    "                             validation_steps=test_samples // batch_size, \n",
    "                             epochs=35, \n",
    "                             callbacks=[csv_logger, checkpointer, progress_printer])\n",
    "\n",
    "# Save the model\n",
    "model.save('model_trained_101class_inceptionv3den3.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0cc882-cb34-4790-80b8-4fd3625cd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\kurt_\\best_model_101class_inceptionv3den3.hdf5\"\n",
    "test_data_path = r\"C:\\Users\\kurt_\\Desktop\\food-101\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f59433-7167-403a-9ab5-eca7174aebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans metriklerini hesaplamak için fonksiyon tanımla\n",
    "def calculate_metrics(model, test_gen):\n",
    "    # Modelden tahminler yap\n",
    "    predictions = model.predict(test_gen)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Gerçek sınıfları al\n",
    "    true_classes = test_gen.classes\n",
    "    \n",
    "    # Sınıf etiketlerini al\n",
    "    class_labels = list(test_gen.class_indices.keys())\n",
    "\n",
    "    # Doğruluk, hassasiyet, geri çağırma ve F1 puanını hesapla\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "    recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23639f1-d836-498c-a736-f160fd4837b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101000 images belonging to 101 classes.\n",
      "6313/6313 [==============================] - 405s 64ms/step\n",
      "Accuracy: 0.9414950495049504\n",
      "Precision: 0.9454587868753546\n",
      "Recall: 0.9414950495049504\n",
      "F1 Score: 0.9419139984545255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Boyutları tanımla\n",
    "height, width = 331, 331\n",
    "\n",
    "# Batch boyutunu tanımla\n",
    "batch_size = 16\n",
    "\n",
    "# Test veri üreteci oluştur\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_gen = test_data_gen.flow_from_directory(test_data_path, target_size=(height, width), batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Modeli yükle\n",
    "model = load_model(model_path, compile=False)\n",
    "\n",
    "# Performans metriklerini hesapla\n",
    "accuracy, precision, recall, f1_score = calculate_metrics(model, test_gen)\n",
    "\n",
    "# Hesaplanan metrikleri yazdır\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27533fdc-d670-4d08-bd11-05c729ec2715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
